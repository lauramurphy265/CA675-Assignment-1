#Registering piggybank.jar in order to import data
REGISTER /usr/local/hadoop/Pig/pig-0.17.0/contrib/piggybank/java/piggybank.jar

#Loading datasets into Pig
A = LOAD 'Queries_1.csv' USING org.apache.pig.piggybank.storage.CSVExcelStorage(',','YES_MULTILINE') as (Id:int,ViewCount:int, Score:int, Body:chararray, Title:chararray);
B = LOAD 'Queries_2.csv' USING org.apache.pig.piggybank.storage.CSVExcelStorage(',','YES_MULTILINE') as (Id:int,ViewCount:int, Score:int, Body:chararray, Title:chararray);
C = LOAD 'Queries_3.csv' USING org.apache.pig.piggybank.storage.CSVExcelStorage(',','YES_MULTILINE') as (Id:int,ViewCount:int, Score:int, Body:chararray, Title:chararray);
D = LOAD 'Queries_4.csv' USING org.apache.pig.piggybank.storage.CSVExcelStorage(',','YES_MULTILINE') as (Id:int,ViewCount:int, Score:int, Body:chararray, Title:chararray);

#Cleaning datasets
A_clean = FOREACH A GENERATE Id,Score,ViewCount, REPLACE(REPLACE(REPLACE(REPLACE(Body,'\\n',''),'\\r',''),'\\r\\n',''),'<br>',''),REPLACE(REPLACE(REPLACE(REPLACE(Title,'\\n',''),'\\r',''),'\\r\\n',''),'<br>','');
B_clean = FOREACH B GENERATE Id,Score,ViewCount, REPLACE(REPLACE(REPLACE(REPLACE(Body,'\\n',''),'\\r',''),'\\r\\n',''),'<br>',''),REPLACE(REPLACE(REPLACE(REPLACE(Title,'\\n',''),'\\r',''),'\\r\\n',''),'<br>','');
C_clean = FOREACH C GENERATE Id,Score,ViewCount, REPLACE(REPLACE(REPLACE(REPLACE(Body,'\\n',''),'\\r',''),'\\r\\n',''),'<br>',''),REPLACE(REPLACE(REPLACE(REPLACE(Title,'\\n',''),'\\r',''),'\\r\\n',''),'<br>','');
D_clean = FOREACH D GENERATE Id,Score,ViewCount, REPLACE(REPLACE(REPLACE(REPLACE(Body,'\\n',''),'\\r',''),'\\r\\n',''),'<br>',''),REPLACE(REPLACE(REPLACE(REPLACE(Title,'\\n',''),'\\r',''),'\\r\\n',''),'<br>','');

# Join 4 datasets together
fullset_clean = UNION A_clean,B_clean,C_clean,D_clean;

#Saving down full dataset to be used in Hive
STORE fullset_clean INTO '/usr/local/hadoop/HiveData' USING PigStorage(',');

